Profile: I am Chao Wang. I am a Principal Applied Scientist at Microsoft. I am reachable at wangchao@microsoft.com. I am operating at a senior research-to-production tier, aligning with Partner and Group-level Engineering Directors and executing with Principal Software Engineering Managers and core Software Engineers. I collaborate closely with Ramesh R, Qiongfang Zhang, Bingqian Shen, Bo Lu, Yu Jin, Meng Zhou, and Wanqin Cao. I am focused on translating scientific theory into scalable engineering frameworks and bridging research-heavy initiatives with product-driven engineering cycles. I have expertise in applied science-to-engineering translation, cross-functional technical leadership, and productionizing AI workflows.

Description: Action-oriented catch-up across SOX/RTC and adjacent agent tooling: follow-ups from your AI prompt session, plus key automation ideas from OS migration tooling and PR-review agent workflows.

Andrew: Hi Chao, today is Wednesday, February 4, 2026.
Andrew: From your SOX RTC bug bash session: the room’s main pull was toward making the “counterintuitive” prompting ideas more repeatable without getting brittle.
Ava: The sharpest pushback was on interpretability of that sampling graph—questions stayed on whether the “ideal” region implies forcing outputs beyond the model’s natural distribution, and what the axes mean in practice.
Andrew: Net outcome: there’s interest in a follow-up session next Friday, specifically to go deeper on the counterintuitive techniques and how to keep them stable across model upgrades.
Ava: The other thread that landed: prompt iteration can overfit. The practical next step people want is guidance on when to stop iterating and “refactor” prompts back into something general-purpose.
Andrew: Tooling-wise, the group fixated on versioning and rollback mechanics for spec-driven workflows—restore checkpoints were the concrete hook people latched onto, and they’ll want more operational detail next time.

Ava: Switching to migration tooling—Package Modernizer is trending toward smaller, more reviewable change sets.
Andrew: A concrete suggestion from the audience was to break the migration work into modular mini-steps with code review after each step, to reduce context bloat and keep agents on-rails; the presenter signaled they’ll split big PRs into smaller commits.
Ava: Another takeaway: the agent is operating repo-level, sequencing projects via dependency graphs, then generating design options when incompatibilities show up—so teams should expect to choose between conservative vs aggressive designs, not just accept a single rewrite.

Andrew: OS Porter: the discussion moved quickly from “inner loop” to “auto loop.”
Ava: The most actionable idea was adding a simple script hook after inner-loop completion—teams could plug in their own rollout, rollback, or extra validation via ADO APIs without OS Porter having to own deployment logic.
Andrew: The OS Porter team didn’t commit to dates, but they were receptive—current priority is finishing inner-loop automation, with openness to async hook exploration afterward.

Ava: Agent Engineering learning series: the PR review tool demo basically reframed code review as a context-assembly problem first, and a commenting problem second.
Andrew: The tool’s differentiator is pulling PR-adjacent context—work items, meeting/design notes, and referenced code—into a bounded work tree to stay under token limits, then running preset review modes like bug hunt, perf, security, or custom team presets.
Ava: The “auto-fix as separate commits” approach got attention because it’s reversible and auditable—small mechanical fixes land as their own commits, with SHAs as proof, and humans can still gate the merge.
Andrew: Questions clustered around accuracy and integration: how it avoids missing context, and whether it interferes with local IDE workflows. The answer was “minimal files, separate terminal, no file lock issues.”
Ava: Forward-looking: people pushed for an extension model—plugins users can append—and the maintainer said the backend is designed for it, with a plan to share a binary plus source for community contributions.

Andrew: Your next concrete moves: lock the follow-up slot for next Friday and pick one “stability” theme—either prompt refactoring to avoid overfit, or model-upgrade drift and how to regression-test prompts.
Ava: And if SOX cares about automation leverage, the two high-ROI asks to socialize are the OS Porter post-inner-loop script hook, and the PR tool’s extension/plugin interface—both are small surface areas with outsized workflow impact.